{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAP HANA Cloud Vector Engine\n",
    "\n",
    ">[SAP HANA Cloud Vector Engine](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/sap-hana-cloud-sap-hana-database-vector-engine-guide) is a vector store fully integrated into the `SAP HANA Cloud` database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install the `langchain-hana` external integration package, as well as the other packages used throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install langchain-hana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "\n",
    "Ensure your SAP HANA instance is running. Load your credentials from environment variables and create a connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from hdbcli import dbapi\n",
    "\n",
    "load_dotenv()\n",
    "# Use connection settings from the environment\n",
    "\n",
    "connection = dbapi.connect(\n",
    "    address=os.environ.get(\"HANA_DB_ADDRESS\"),\n",
    "    port=os.environ.get(\"HANA_DB_PORT\"),\n",
    "    user=os.environ.get(\"HANA_DB_USER\"),\n",
    "    password=os.environ.get(\"HANA_DB_PASSWORD\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about SAP HANA in [What is SAP HANA?](https://www.sap.com/products/data-cloud/hana/what-is-sap-hana.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "To initialize a `HanaDB` vector store, you need a database connection and an embedding instance. SAP HANA Cloud Vector Engine supports both external and internal embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using External Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Internal Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can compute embeddings directly in SAP HANA using its native `VECTOR_EMBEDDING()` function. To enable this, create an instance of `HanaInternalEmbeddings` with your internal model ID and pass it to `HanaDB`. Note that the `HanaInternalEmbeddings` instance is specifically designed for use with `HanaDB` and is not intended for use with other vector store implementations. For more information about internal embedding, see the [SAP HANA VECTOR_EMBEDDING Function](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/vector-embedding-function-vector).\n",
    "\n",
    "> **Caution:** Ensure NLP is enabled in your SAP HANA Cloud instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_hana import HanaInternalEmbeddings\n",
    "\n",
    "embeddings = HanaInternalEmbeddings(internal_embedding_model_id=\"SAP_NEB.20240715\")\n",
    "\n",
    "# optionally, you can specify a remote source to use models from your deployed SAP AI CORE instance\n",
    "\n",
    "# embeddings = HanaInternalEmbeddings(\n",
    "#     internal_embedding_model_id=\"your-embedding-model-id\",\n",
    "#     remote_source=\"your-remote-source-name\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your connection and embedding instance, create the vector store by passing them to `HanaDB` along with a table name for storing vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_hana import HanaDB\n",
    "\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=\"MY_TABLE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "\n",
    "Once you have created your vector store, we can interact with it by adding and deleting different items.\n",
    "\n",
    "### Add items to vector store\n",
    "\n",
    "We can add items to our vector store by using the `add_documents` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [Document(page_content=\"Some text\"), Document(page_content=\"Other docs\")]\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add documents with metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"foo\",\n",
    "        metadata={\"start\": 100, \"end\": 150, \"doc_name\": \"foo.txt\", \"quality\": \"bad\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"bar\",\n",
    "        metadata={\"start\": 200, \"end\": 250, \"doc_name\": \"bar.txt\", \"quality\": \"good\"},\n",
    "    ),\n",
    "]\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete items from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete(filter={\"quality\": \"bad\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query vector store\n",
    "\n",
    "### Query directly\n",
    "\n",
    "#### Similarity search\n",
    "\n",
    "Performing a simple similarity search with filtering on metadata can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='bad'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "foo\n",
      "{'start': 100, 'end': 150, 'doc_name': 'foo.txt', 'quality': 'bad'}\n"
     ]
    }
   ],
   "source": [
    "docs = db.similarity_search(\"foobar\", k=2, filter={\"quality\": \"bad\"})\n",
    "# With filtering on \"quality\"==\"bad\", only one document should be returned\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMR search\n",
    "\n",
    "Performing a Maximal Marginal Relevance (MMR) with filtering on metadata search can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='bad'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "foo\n",
      "{'start': 100, 'end': 150, 'doc_name': 'foo.txt', 'quality': 'bad'}\n"
     ]
    }
   ],
   "source": [
    "docs = db.max_marginal_relevance_search(\"foobar\", k=2, fetch_k=5, filter={\"quality\": \"bad\"})\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by turning into retriever\n",
    "\n",
    "You can also transform the vector store into a retriever for easier usage in your chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='good'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "bar\n",
      "{'start': 200, 'end': 250, 'doc_name': 'bar.txt', 'quality': 'good'}\n"
     ]
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "docs = retriever.invoke(\"foobar\", filter={\"quality\": \"good\"})\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance similarity algorithm\n",
    "\n",
    "`HanaDB` supports the following distance similarity algorithms:\n",
    "- Cosine Similarity (default)\n",
    "- Euclidian Distance (L2)\n",
    "\n",
    "You can specify the distance strategy when initializing the `HanaDB` instance by using the `distance_strategy` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_hana.utils import DistanceStrategy\n",
    "db = HanaDB(\n",
    "    embedding=embeddings,\n",
    "    connection=connection,\n",
    "    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,\n",
    "    # distance_strategy=DistanceStrategy.COSINE_SIMILARITY,  # (default)\n",
    "    table_name=\"MY_TABLE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a HNSW index\n",
    "\n",
    "A vector index can significantly speed up top-k nearest neighbor queries for vectors. Users can create a Hierarchical Navigable Small World (HNSW) vector index using the `create_hnsw_index` function.\n",
    "\n",
    "For more information about creating an index at the database level, please refer to the [official documentation](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/create-vector-index-statement-data-definition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=\"MY_TABLE\"\n",
    ")\n",
    "db.create_hnsw_index(\n",
    "    index_name=\"MY_TABLE_index\",\n",
    "    m=100,  # Max number of neighbors per graph node (valid range: 4 to 1000)\n",
    "    ef_construction=200,  # Max number of candidates during graph construction (valid range: 1 to 100000)\n",
    "    ef_search=500,  # Min number of candidates during the search (valid range: 1 to 100000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no other parameters are specified, the default values will be used\n",
    "\n",
    "Default values: m=64, ef_construction=128, ef_search=200\n",
    "\n",
    "The default index name will be: \"\\<TABLE_NAME>_idx\"\n",
    "\n",
    "## Advanced filtering\n",
    "\n",
    "In addition to the basic value-based filtering capabilities, it is possible to use more advanced filtering.\n",
    "The table below shows the available filter operators.\n",
    "\n",
    "| Operator | Semantic                 |\n",
    "|----------|-------------------------|\n",
    "| `$eq`    | Equality (==)           |\n",
    "| `$ne`    | Inequality (!=)         |\n",
    "| `$lt`    | Less than (&lt;)           |\n",
    "| `$lte`   | Less than or equal (&lt;=) |\n",
    "| `$gt`    | Greater than (>)        |\n",
    "| `$gte`   | Greater than or equal (>=) |\n",
    "| `$in`    | Contained in a set of given values  (in)    |\n",
    "| `$nin`   | Not contained in a set of given values  (not in)  |\n",
    "| `$between` | Between the range of two boundary values |\n",
    "| `$like`  | Text equality based on the \"LIKE\" semantics in SQL (using \"%\" as wildcard)  |\n",
    "| `$contains` | Filters documents containing a specific keyword |\n",
    "| `$and`   | Logical \"and\", supporting two or more operands |\n",
    "| `$or`    | Logical \"or\", supporting two or more operands |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare some test documents\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"First\",\n",
    "        metadata={\"name\": \"Adam Smith\", \"is_active\": True, \"id\": 1, \"height\": 10.0},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Second\",\n",
    "        metadata={\"name\": \"Bob Johnson\", \"is_active\": False, \"id\": 2, \"height\": 5.7},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Third\",\n",
    "        metadata={\"name\": \"Jane Doe\", \"is_active\": True, \"id\": 3, \"height\": 2.4},\n",
    "    ),\n",
    "]\n",
    "\n",
    "db = HanaDB(\n",
    "    connection=connection,\n",
    "    embedding=embeddings,\n",
    "    table_name=\"LANGCHAIN_DEMO_ADVANCED_FILTER\",\n",
    ")\n",
    "\n",
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})\n",
    "db.add_documents(docs)\n",
    "\n",
    "\n",
    "# Helper function for printing filter results\n",
    "def print_filter_result(result):\n",
    "    if len(result) == 0:\n",
    "        print(\"<empty result>\")\n",
    "    for doc in result:\n",
    "        print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering with `$ne`, `$gt`, `$gte`, `$lt`, `$lte`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: {'id': {'$ne': 1}}\n",
      "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
      "Filter: {'id': {'$gt': 1}}\n",
      "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
      "Filter: {'id': {'$gte': 1}}\n",
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
      "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
      "Filter: {'id': {'$lt': 1}}\n",
      "<empty result>\n",
      "Filter: {'id': {'$lte': 1}}\n",
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n"
     ]
    }
   ],
   "source": [
    "advanced_filter = {\"id\": {\"$ne\": 1}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"id\": {\"$gt\": 1}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"id\": {\"$gte\": 1}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"id\": {\"$lt\": 1}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"id\": {\"$lte\": 1}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering with `$between`, `$in`, `$nin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='Adam Smith'\n",
      "Plain SQL Placeholder '?' for value='Bob Johnson'\n",
      "Plain SQL Placeholder '?' for value='Adam Smith'\n",
      "Plain SQL Placeholder '?' for value='Bob Johnson'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: {'id': {'$between': (1, 2)}}\n",
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
      "Filter: {'name': {'$in': ['Adam Smith', 'Bob Johnson']}}\n",
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
      "Filter: {'name': {'$nin': ['Adam Smith', 'Bob Johnson']}}\n",
      "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n"
     ]
    }
   ],
   "source": [
    "advanced_filter = {\"id\": {\"$between\": (1, 2)}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"name\": {\"$in\": [\"Adam Smith\", \"Bob Johnson\"]}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"name\": {\"$nin\": [\"Adam Smith\", \"Bob Johnson\"]}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text filtering with `$like`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='a%'\n",
      "Plain SQL Placeholder '?' for value='%a%'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: {'name': {'$like': 'a%'}}\n",
      "<empty result>\n",
      "Filter: {'name': {'$like': '%a%'}}\n",
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
      "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n"
     ]
    }
   ],
   "source": [
    "advanced_filter = {\"name\": {\"$like\": \"a%\"}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"name\": {\"$like\": \"%a%\"}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text filtering with `$contains`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='bob'\n",
      "Plain SQL Placeholder '?' for value='bo'\n",
      "Plain SQL Placeholder '?' for value='Adam Johnson'\n",
      "Plain SQL Placeholder '?' for value='Adam Smith'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: {'name': {'$contains': 'bob'}}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
      "Filter: {'name': {'$contains': 'bo'}}\n",
      "<empty result>\n",
      "Filter: {'name': {'$contains': 'Adam Johnson'}}\n",
      "<empty result>\n",
      "Filter: {'name': {'$contains': 'Adam Smith'}}\n",
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n"
     ]
    }
   ],
   "source": [
    "advanced_filter = {\"name\": {\"$contains\": \"bob\"}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"name\": {\"$contains\": \"bo\"}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"name\": {\"$contains\": \"Adam Johnson\"}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"name\": {\"$contains\": \"Adam Smith\"}}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined filtering with `$and`, `$or`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='bob'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: {'$or': [{'id': 1}, {'name': 'bob'}]}\n",
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
      "Filter: {'$and': [{'id': 1}, {'id': 2}]}\n",
      "<empty result>\n",
      "Filter: {'$or': [{'id': 1}, {'id': 2}, {'id': 3}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='bob'\n",
      "Plain SQL Placeholder '?' for value='johnson'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
      "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
      "Filter: {'$and': [{'name': {'$contains': 'bob'}}, {'name': {'$contains': 'johnson'}}]}\n",
      "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n"
     ]
    }
   ],
   "source": [
    "advanced_filter = {\"$or\": [{\"id\": 1}, {\"name\": \"bob\"}]}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"$and\": [{\"id\": 1}, {\"id\": 2}]}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\"$or\": [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}]}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
    "\n",
    "advanced_filter = {\n",
    "    \"$and\": [{\"name\": {\"$contains\": \"bob\"}}, {\"name\": {\"$contains\": \"johnson\"}}]\n",
    "}\n",
    "print(f\"Filter: {advanced_filter}\")\n",
    "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage for retrieval-augmented generation\n",
    "\n",
    "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
    "\n",
    "- [Tutorials](https://docs.langchain.com/oss/python/langchain/rag)\n",
    "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
    "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval)\n",
    "\n",
    "## Standard tables vs. \"custom\" tables with vector data\n",
    "\n",
    "As default behaviour, the table for the embeddings is created with 3 columns:\n",
    "\n",
    "- A column `VEC_TEXT`, which contains the text of the Document\n",
    "- A column `VEC_META`, which contains the metadata of the Document\n",
    "- A column `VEC_VECTOR`, which contains the embeddings-vector of the Document's text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the vector DB with a new table\n",
    "db = HanaDB(\n",
    "    connection=connection, embedding=embeddings, table_name=\"LANGCHAIN_DEMO_NEW_TABLE\"\n",
    ")\n",
    "\n",
    "# Delete already existing entries from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# Add a simple document with some metadata\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"A simple document\",\n",
    "        metadata={\"start\": 100, \"end\": 150, \"doc_name\": \"simple.txt\"},\n",
    "    )\n",
    "]\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the columns in table \"LANGCHAIN_DEMO_NEW_TABLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('VEC_META', 'NCLOB')\n",
      "('VEC_TEXT', 'NCLOB')\n",
      "('VEC_VECTOR', 'REAL_VECTOR')\n"
     ]
    }
   ],
   "source": [
    "cur = connection.cursor()\n",
    "cur.execute(\n",
    "    \"SELECT COLUMN_NAME, DATA_TYPE_NAME FROM SYS.TABLE_COLUMNS WHERE SCHEMA_NAME = CURRENT_SCHEMA AND TABLE_NAME = 'LANGCHAIN_DEMO_NEW_TABLE'\"\n",
    ")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the value of the inserted document in the three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple document\n",
      "{\"start\": 100, \"end\": 150, \"doc_name\": \"simple.txt\"}\n",
      "[-0.01989901,0.027851747,0.0020877712,0.005429436,0.013132469,-0.0076223738,0.0111856805,0.016828882,-0.026602358,-0.052853536,0.009006557,-0.010468711,-0.05485793,0.007335201,-0.010426161,0.03479807,0.050378572,-0.020091077,-0.0014458451,-0.030360341,-0.027881699,0.034227487,0.03142381,0.012528219,0.020661771,0.005478361,0.04231155,0.003134585,-0.0795535,0.038250014,0.021077449,-0.0045408322,-0.012608559,-0.017505696,0.016195422,-0.024862682,0.020381251,-0.008152154,-0.010130064,-0.014113081,-0.015686149,0.0053738304,0.0052879346,0.010699794,-0.03255791,-0.0037708033,-0.058432374,0.036250237,-0.06431493,0.02836358,-0.076346755,0.032799967,-0.006052708,0.009781954,-0.050784424,0.063515924,-0.01097006,-0.02970471,-0.0004907463,-0.019697318,0.017844269,0.015163101,0.060964018,0.032544035,0.034033075,-0.00017372223,0.00077666854,0.0379511,-0.03839218,0.0066685076,-0.013823626,0.0036996289,-0.01915847,-0.022761023,0.03917062,-0.02486851,0.03126547,0.019683246,0.02845812,0.026247242,0.02629836,0.022584325,-0.008870727,0.046628784,-0.012451768,-0.0033297252,-0.048984658,0.034240913,-0.01819802,0.06462749,0.010162172,-0.050411742,0.031287834,0.041077983,-0.027780121,-0.041659143,0.025847219,0.00757655,0.014813248,0.029158274,-0.02556807,-0.022439646,0.056261647,-0.047706183,-0.089545436,-0.008552557,-0.009712075,0.029496737,0.046284433,0.036136333,0.02785729,-0.028584614,-0.03562552,0.00785165,-0.061855603,0.0600847,0.040957954,0.008066473,-0.012237005,-0.046031687,0.03595375,0.030235061,0.03302402,0.0786294,0.016957948,-0.008046753,-0.00034559114,0.06482706,-0.034021165,-0.02725157,0.00013924485,0.04337223,0.022386136,-0.0035941917,0.011528275,-0.003155958,0.0007997495,0.006195791,0.025836041,-0.012935744,0.021461539,-0.019567693,-0.00030398197,-0.0072785057,0.014345571,-0.031250365,-0.010712374,-0.039979234,-0.038386926,0.013367088,-0.01678071,-0.027426928,0.057314914,-0.0064354795,-0.021544019,0.046119586,0.0056298063,0.028135875,-0.0018046005,-0.0072483034,0.024289848,0.0045110085,-0.0077491836,-0.004086904,-0.03369009,0.03432962,0.023007566,0.021550538,0.0034630538,-0.00806897,-0.0064466186,-0.022842238,0.017843088,0.018947208,-0.0335105,0.024657449,0.07809476,0.025572456,0.028574066,-0.013540921,-0.07341529,0.026027048,0.013741467,-0.0048916796,0.022198096,-0.026809143,0.049435478,0.016300132,-0.021394538,-0.035377618,-0.061855238,-0.0720844,0.054079544,-0.0057802093,0.029692957,-0.0052133463,-0.0112422705,0.070882775,-0.001215704,0.05501579,0.02016303,0.029906066,0.072239704,-0.015112354,-0.02336172,0.03569134,0.04537264,-0.0029037409,-0.01193133,-0.020361634,-0.006698318,0.027031606,0.074193716,-0.0007295922,0.015870688,0.029564532,0.044798356,-0.029742822,0.015833631,-0.042114634,0.003169413,0.01728567,-0.02654753,0.020524928,-0.025597854,0.10481139,0.051641908,-0.047329705,0.004294053,-0.03895679,-0.033209234,-0.046039324,0.011573974,0.008465796,0.003168297,0.02543247,-0.02059665,-0.028129265,0.048439186,-0.03842176,0.038713884,0.031956702,-0.0013289424,0.04184499,0.028606245,-0.00094302977,0.025955008,0.0007870377,0.009614109,-0.006793192,0.00010432227,-0.024208507,0.03855544,-0.015198115,-0.005427116,-0.029340252,-0.010982607,-0.021381803,0.04143611,0.07513541,-0.042554956,0.024380915,0.03114258,0.038891856,-0.024599755,-0.079596475,-0.025412723,0.032207962,0.003974358,0.030313706,0.0042010364,0.051434886,-0.0100137675,0.0030687144,0.0015056346,-0.013155933,0.0638795,0.0034099168,-0.05901574,-0.03058333,0.019512204,0.05384727,0.0077188252,-0.046236087,0.023868917,-0.060824562,0.057814807,-0.029269652,-0.01792585,-0.007902022,-0.011093344,0.022311712,0.014030799,-0.015343487,0.036244866,0.030266976,-0.0036139842,-0.035932105,0.018739775,-0.022347817,0.065680794,-0.0016907271,0.017417844,0.010788654,0.0016598079,0.009836994,0.0000071829804,-0.052797187,-0.27219024,0.018742561,-0.013345932,-0.057622045,0.007196072,-0.025178755,0.013911934,-0.057052303,-0.050484274,0.02925021,-0.041732524,-0.0025773675,0.0027852661,0.028208548,0.03929585,0.013776068,-0.025321292,-0.009681609,-0.000016077227,0.00018389492,-0.019491753,-0.053033844,-0.0034327067,0.019520236,0.01628624,0.02564141,-0.020202132,-0.008869148,-0.05098884,-0.0046400228,0.036461715,-0.029227853,0.028814482,-0.012898364,-0.016982196,-0.013033734,0.032976035,-0.0037252915,-0.011377112,-0.026087811,-0.021876194,-0.0162943,0.01574377,-0.02734516,0.03322542,-0.025936514,-0.017244732,-0.053018898,0.0050629782,0.043938488,-0.068421304,0.0061881263,-0.019757137,0.01577852,-0.02391199,-0.016064772,-0.0039113346,-0.0015400476,-0.0053236447,0.0023266096,0.010828839,-0.06464557,-0.008435578,-0.017192451,-0.011821209,-0.037851382,-0.046821464,-0.04583953,0.046310335,0.06841693,-0.015749518,0.0028458366,-0.021920687,-0.067162044,0.001571043,-0.028425785,-0.023773566,0.00022759165,0.006216151,0.029274022,-0.032682028,-0.013562522,0.022363016,0.02894768,0.010976707,-0.021201046,0.03290002,-0.002651181,-0.022476092,-0.055219542,0.051065404,0.0040039704,-0.0060067824,0.03992705,0.034428656,-0.021108793,0.009096087,-0.048252042,0.028715229,-0.0019393908,0.07144596,-0.018340444,-0.0020481348,0.008924436,-0.034856502,-0.008143347,-0.06509155,0.017043084,0.019200824,0.0009032754,-0.022352254,0.006640626,0.012139817,-0.056238633,0.016027125,-0.046013266,0.016065406,0.03687627,-0.037419032,-0.042021513,-0.013619167,0.030456295,-0.032448664,-0.018149855,-0.09978539,0.033120364,0.024034819,-0.016284993,0.0006760896,-0.0062357225,0.010654877,-0.017417043,0.008603452,-0.032686237,0.03647421,-0.015410158,-0.028899869,-0.042524308,-0.017462367,-0.009166849,-0.0072271167,-0.025718028,-0.00035795322,0.024519876,0.018333055,-0.021926986,-0.017133936,0.009460423,-0.0071656015,0.002897368,-0.028783774,0.010654452,-0.054799303,-0.0684239,-0.053608816,-0.024930261,0.016284268,-0.008134919,-0.02701318,-0.037145738,-0.010730847,-0.038020622,-0.040161353,-0.0021451346,0.04684168,0.04519117,0.003131001,0.0028911948,0.0033281941,0.007010897,0.011277195,-0.033707585,-0.008678424,-0.007978228,-0.03165127,0.04034013,0.020941481,0.06397887,0.017816836,0.022875614,0.044017896,-0.05825891,0.004507331,-0.018638643,0.06956022,-0.017867884,-0.016970104,-0.027826026,-0.027469253,0.0034053568,0.033808034,0.0015826081,-0.020179993,0.02046805,-0.02813624,-0.077702306,-0.0066713267,0.016531033,0.00046073576,-0.01204702,-0.009492228,-0.026495839,-0.027132295,0.0017881999,0.014875524,-0.03522582,0.018398969,-0.022554213,0.006199621,0.026870117,-0.013384736,-0.04537217,-0.020819155,-0.048357558,0.0052889753,-0.031459007,-0.028191993,-0.04676513,-0.0013590817,-0.04521869,-0.002087214,0.0017097705,-0.04352818,0.021007044,-0.018390834,0.026296059,-0.035806973,-0.01774328,0.0024806699,-0.04288428,0.012621288,-0.00959085,0.019002112,0.05102563,-0.036652487,0.029802257,-0.025948828,0.024679432,-0.0072699008,0.063175306,-0.0034462884,0.026957901,-0.0108749345,-0.02823484,0.0023655193,-0.006031357,-0.0075715203,-0.05018634,-0.020389529,0.07865181,-0.012070581,-0.012056079,-0.038312916,-0.0380341,0.041369226,-0.012359648,-0.031132055,0.03338011,-0.034740336,0.022297882,0.043205187,-0.023555545,-0.009742378,0.018801197,0.091935635,0.010892685,-0.023984231,0.0035604544,0.04675372,-0.05410293,-0.01611756,-0.0577573,-0.023582632,-0.0022834379,0.03142631,-0.013179029,-0.018850133,-0.025837786,0.018612208,-0.037684303,-0.019189976,0.030581571,0.015951851,0.019893209,0.02054096,-0.028778873,-0.002345399,0.058707427,-0.054266587,0.028768852,-0.020113729,0.019649586,-0.02295743,0.028631391,0.016209677,0.010336113,0.054121327,0.05140959,-0.028039472,0.03183185,-0.028648632,0.04065895,0.037421353,-0.020070927,-0.026495902,0.04457745,-0.031658474,-0.04790267,-0.030090978,0.009962139,-0.060865093,-0.04588169,0.06468015,-0.0105404435,-0.060970798,-0.03135681,-0.005898898,-0.044850904,-0.022531131,0.00984976,0.009488055,-0.000509457,0.016838169,-0.0005311489,0.004614894,0.06333561,-0.041707497,0.045391634,-0.0025138515,0.06616112,0.07109145,0.075778686,-0.018873533,0.059792276,-0.022849508,-0.034104086,0.0066301846,0.002697678,0.024394898,0.03848518,-0.03161074,0.026250957,0.009876664,0.06320382,0.034298994,-0.029908797,0.019930584,0.02228651,0.02449713,0.014172099,0.019311758,0.028252931,0.007883785,-0.009547901,0.044278637,-0.028485678,0.009499035,0.007977718,-0.04950513,0.024522288,0.00021511868,0.029424138,0.06294456,0.030110272,-0.03978191,-0.009911188,0.0053873397,0.009834525,-0.02790764,0.01505104,-0.016024819,0.0083129555,0.0029336119,0.04107866,0.0151524395,0.022860708,0.0041653807,0.030447783,0.0056278054,0.03238138,0.0005043394,-0.039285418,-0.032075558,0.0017019082,-0.020248089,-0.041185766,0.0035143646,-0.015339464,0.021103805,-0.04271668,-0.018123785,-0.05990817,0.0167069,0.013596998,-0.02066011,-0.0105016045,0.017353535,0.0630231,0.00420019,0.009579244,0.04144753,-0.032464374,-0.059544224,-0.02165071,-0.0031286187,0.04700925,0.009172865,0.00011114931,-0.078203954,0.013928029,0.033291865,0.016956165,-0.06133999,0.014088918,-0.03073704,-0.006619467,0.042982716,0.013173926,0.0092108175,-0.029604815,-0.011502728,0.01125818,0.022506282,0.06411872,-0.028196411,0.06312326,0.009218234,0.029649472,-0.025651984,0.028154911,-0.008831545,-0.016822012,-0.0035703937,-0.00037355852,-0.03431089,-0.04213108,-0.05012605,0.021773398,-0.021167187,-0.03609368,0.015933352,0.021932924,0.021861909,-0.019671675,-0.0037314063,-0.017420532,-0.027999057,-0.013815314,-0.058415893,-0.029574567,0.010510825,0.013269977,-0.016479064,-0.029248135,0.016258953,-0.020191519,-0.026926616,0.018324837,0.009469634,0.04312701]\n"
     ]
    }
   ],
   "source": [
    "cur = connection.cursor()\n",
    "cur.execute(\n",
    "    \"SELECT VEC_TEXT, VEC_META, TO_NVARCHAR(VEC_VECTOR) FROM LANGCHAIN_DEMO_NEW_TABLE LIMIT 1\"\n",
    ")\n",
    "rows = cur.fetchall()\n",
    "print(rows[0][0])  # The text\n",
    "print(rows[0][1])  # The metadata\n",
    "print(rows[0][2])  # The vector\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom tables must have at least three columns that match the semantics of a standard table\n",
    "\n",
    "- A column with type `NCLOB` or `NVARCHAR` for the text/context of the embeddings\n",
    "- A column with type `NCLOB` or `NVARCHAR` for the metadata\n",
    "- A column with type `REAL_VECTOR` or `HALF_VECTOR` for the embedding vector\n",
    "\n",
    "The table can contain additional columns. When new Documents are inserted into the table, these additional columns must allow NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Some other text\n",
      "{\"start\": 400, \"end\": 450, \"doc_name\": \"other.txt\"}\n",
      "<memory at 0x7f0b40cf8400>\n"
     ]
    }
   ],
   "source": [
    "# Create a new table \"MY_OWN_TABLE_ADD\" with three \"standard\" columns and one additional column\n",
    "my_own_table_name = \"MY_OWN_TABLE_ADD\"\n",
    "cur = connection.cursor()\n",
    "cur.execute(\n",
    "    (\n",
    "        f\"CREATE TABLE {my_own_table_name} (\"\n",
    "        \"SOME_OTHER_COLUMN NVARCHAR(42), \"\n",
    "        \"MY_TEXT NVARCHAR(2048), \"\n",
    "        \"MY_METADATA NVARCHAR(1024), \"\n",
    "        \"MY_VECTOR REAL_VECTOR )\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a HanaDB instance with the own table\n",
    "db = HanaDB(\n",
    "    connection=connection,\n",
    "    embedding=embeddings,\n",
    "    table_name=my_own_table_name,\n",
    "    content_column=\"MY_TEXT\",\n",
    "    metadata_column=\"MY_METADATA\",\n",
    "    vector_column=\"MY_VECTOR\",\n",
    ")\n",
    "\n",
    "# Add a simple document with some metadata\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Some other text\",\n",
    "        metadata={\"start\": 400, \"end\": 450, \"doc_name\": \"other.txt\"},\n",
    "    )\n",
    "]\n",
    "db.add_documents(docs)\n",
    "\n",
    "# Check if data has been inserted into our own table\n",
    "cur.execute(f\"SELECT * FROM {my_own_table_name} LIMIT 1\")\n",
    "rows = cur.fetchall()\n",
    "print(rows[0][0])  # Value of column \"SOME_OTHER_DATA\". Should be NULL/None\n",
    "print(rows[0][1])  # The text\n",
    "print(rows[0][2])  # The metadata\n",
    "print(rows[0][3])  # The vector\n",
    "\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add another document and perform a similarity search on the custom table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Some more text\n",
      "--------------------------------------------------------------------------------\n",
      "Some other text\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Some more text\",\n",
    "        metadata={\"start\": 800, \"end\": 950, \"doc_name\": \"more.txt\"},\n",
    "    )\n",
    "]\n",
    "db.add_documents(docs)\n",
    "\n",
    "query = \"What's up?\"\n",
    "docs = db.similarity_search(query, k=2)\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter performance optimization with custom columns\n",
    "\n",
    "To allow flexible metadata values, all metadata is stored as JSON in the metadata column by default. If some of the used metadata keys and value types are known, they can be stored in additional columns instead by creating the target table with the key names as column names and passing them to the HanaDB constructor via the `specific_metadata_columns` list. Metadata keys that match those values are copied into the special column during insert. Filters use the special columns instead of the metadata JSON column for keys in the `specific_metadata_columns` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters on this value are very performant\n",
      "Some other text\n",
      "{\"start\": 400, \"end\": 450, \"doc_name\": \"other.txt\", \"CUSTOMTEXT\": \"Filters on this value are very performant\"}\n",
      "<memory at 0x7f0b40cf8940>\n"
     ]
    }
   ],
   "source": [
    "# Create a new table \"PERFORMANT_CUSTOMTEXT_FILTER\" with three \"standard\" columns and one additional column\n",
    "my_own_table_name = \"PERFORMANT_CUSTOMTEXT_FILTER\"\n",
    "cur = connection.cursor()\n",
    "cur.execute(\n",
    "    (\n",
    "        f\"CREATE TABLE {my_own_table_name} (\"\n",
    "        \"CUSTOMTEXT NVARCHAR(500), \"\n",
    "        \"MY_TEXT NVARCHAR(2048), \"\n",
    "        \"MY_METADATA NVARCHAR(1024), \"\n",
    "        \"MY_VECTOR REAL_VECTOR )\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a HanaDB instance with the own table\n",
    "db = HanaDB(\n",
    "    connection=connection,\n",
    "    embedding=embeddings,\n",
    "    table_name=my_own_table_name,\n",
    "    content_column=\"MY_TEXT\",\n",
    "    metadata_column=\"MY_METADATA\",\n",
    "    vector_column=\"MY_VECTOR\",\n",
    "    specific_metadata_columns=[\"CUSTOMTEXT\"],\n",
    ")\n",
    "\n",
    "# Add a simple document with some metadata\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Some other text\",\n",
    "        metadata={\n",
    "            \"start\": 400,\n",
    "            \"end\": 450,\n",
    "            \"doc_name\": \"other.txt\",\n",
    "            \"CUSTOMTEXT\": \"Filters on this value are very performant\",\n",
    "        },\n",
    "    )\n",
    "]\n",
    "db.add_documents(docs)\n",
    "\n",
    "# Check if data has been inserted into our own table\n",
    "cur.execute(f\"SELECT * FROM {my_own_table_name} LIMIT 1\")\n",
    "rows = cur.fetchall()\n",
    "print(\n",
    "    rows[0][0]\n",
    ")  # Value of column \"CUSTOMTEXT\". Should be \"Filters on this value are very performant\"\n",
    "print(rows[0][1])  # The text\n",
    "print(\n",
    "    rows[0][2]\n",
    ")  # The metadata without the \"CUSTOMTEXT\" data, as this is extracted into a sperate column\n",
    "print(rows[0][3])  # The vector\n",
    "\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special columns are completely transparent to the rest of the langchain interface. Everything works as it did before, just more performant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plain SQL Placeholder '?' for value='%value%'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Some more text\n",
      "--------------------------------------------------------------------------------\n",
      "Some other text\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"Some more text\",\n",
    "        metadata={\n",
    "            \"start\": 800,\n",
    "            \"end\": 950,\n",
    "            \"doc_name\": \"more.txt\",\n",
    "            \"CUSTOMTEXT\": \"Another customtext value\",\n",
    "        },\n",
    "    )\n",
    "]\n",
    "db.add_documents(docs)\n",
    "\n",
    "advanced_filter = {\"CUSTOMTEXT\": {\"$like\": \"%value%\"}}\n",
    "query = \"What's up?\"\n",
    "docs = db.similarity_search(query, k=2, filter=advanced_filter)\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sample document \"state_of_the_union.txt\" and create chunks from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 88\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_documents = TextLoader(\n",
    "    \"./state_of_the_union.txt\", encoding=\"UTF-8\"\n",
    ").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "text_chunks = text_splitter.split_documents(text_documents)\n",
    "print(f\"Number of document chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the loaded document chunks to the table. For this example, we delete any previous content from the table which might exist from previous runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db.add_documents(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a query to get the two best-matching document chunks from the ones that were added in the previous step.\n",
    "By default \"Cosine Similarity\" is used for the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "--------------------------------------------------------------------------------\n",
      "As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
      "\n",
      "While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query, k=2)\n",
    "\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the same content with \"Euclidian Distance\". The results shoud be the same as with \"Cosine Similarity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "--------------------------------------------------------------------------------\n",
      "As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
      "\n",
      "While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.\n"
     ]
    }
   ],
   "source": [
    "from langchain_hana.utils import DistanceStrategy\n",
    "\n",
    "db = HanaDB(\n",
    "    embedding=embeddings,\n",
    "    connection=connection,\n",
    "    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,\n",
    "    table_name=\"STATE_OF_THE_UNION\",\n",
    ")\n",
    "db.add_documents(text_chunks)\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query, k=2)\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Maximal Marginal Relevance Search (MMR)\n",
    "\n",
    "`Maximal marginal relevance` optimizes for similarity to query AND diversity among selected documents. The first 20 (fetch_k) items will be retrieved from the DB. The MMR algorithm will then find the best 2 (k) matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "--------------------------------------------------------------------------------\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
      "\n",
      "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
      "\n",
      "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.\n"
     ]
    }
   ],
   "source": [
    "docs = db.max_marginal_relevance_search(query, k=2, fetch_k=20)\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an HNSW Vector Index\n",
    "\n",
    "A vector index can significantly speed up top-k nearest neighbor queries for vectors. Users can create a Hierarchical Navigable Small World (HNSW) vector index using the `create_hnsw_index` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
      "--------------------------------------------------------------------------------\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
      "\n",
      "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
      "\n",
      "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.\n"
     ]
    }
   ],
   "source": [
    "# HanaDB instance uses cosine similarity as default:\n",
    "db_cosine = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=\"STATE_OF_THE_UNION\"\n",
    ")\n",
    "\n",
    "# Attempting to create the HNSW index with default parameters\n",
    "db_cosine.create_hnsw_index()  # If no other parameters are specified, the default values will be used\n",
    "# Default values: m=64, ef_construction=128, ef_search=200\n",
    "# The default index name will be: STATE_OF_THE_UNION_COSINE_idx\n",
    "\n",
    "\n",
    "# Creating a HanaDB instance with L2 distance as the similarity function and defined values\n",
    "db_l2 = HanaDB(\n",
    "    embedding=embeddings,\n",
    "    connection=connection,\n",
    "    table_name=\"STATE_OF_THE_UNION\",\n",
    "    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,  # Specify L2 distance\n",
    ")\n",
    "\n",
    "# This will create an index based on L2 distance strategy.\n",
    "db_l2.create_hnsw_index(\n",
    "    index_name=\"STATE_OF_THE_UNION_L2_index\",\n",
    "    m=100,  # Max number of neighbors per graph node (valid range: 4 to 1000)\n",
    "    ef_construction=200,  # Max number of candidates during graph construction (valid range: 1 to 100000)\n",
    "    ef_search=500,  # Min number of candidates during the search (valid range: 1 to 100000)\n",
    ")\n",
    "\n",
    "# Use L2 index to perform MMR\n",
    "docs = db_l2.max_marginal_relevance_search(query, k=2, fetch_k=20)\n",
    "for doc in docs:\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Key Points**:\n",
    "- **Similarity Function**: The similarity function for the index is **cosine similarity** by default. If you want to use a different similarity function (e.g., `L2` distance), you need to specify it when initializing the `HanaDB` instance.\n",
    "- **Default Parameters**: In the `create_hnsw_index` function, if the user does not provide custom values for parameters like `m`, `ef_construction`, or `ef_search`, the default values (e.g., `m=64`, `ef_construction=128`, `ef_search=200`) will be used automatically. These values ensure the index is created with reasonable performance without requiring user intervention.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
